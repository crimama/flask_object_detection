{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v6.1-274-gda2ee39 Python-3.9.12 torch-1.11.0+cpu CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete  (4 CPUs, 7.9 GB RAM, 95.0/118.1 GB disk)\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5  # clone\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt  # install\n",
    "\n",
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "import cv2 \n",
    "cv2.imwrite('images/img.jpg',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yolov5.ddtect import run\n",
    "a = run(weights = 'yolov5/best.pt',\n",
    "    source = 'images')\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.dataloaders.LoadImages at 0x1ed5fcbbbb0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages\n",
    "source = 'images'\n",
    "imgsz = 640 \n",
    "\n",
    "dataset = LoadImages(source, img_size=imgsz)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Working_Repositary\\\\flask-video-stream\\\\yolov5\\\\data\\\\images'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yolov5.utils.general import check_file\n",
    "check_file('images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5/best.pt'], source=images, data=yolov5\\data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5\\runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5  v6.1-274-gda2ee39 Python-3.9.12 torch-1.11.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7225885 parameters, 0 gradients, 16.5 GFLOPs\n",
      "image 1/9 C:\\Working_Repositary\\flask-video-stream\\images\\img_1.png: 480x640 2 persons, Done. (0.467s)\n",
      "image 2/9 C:\\Working_Repositary\\flask-video-stream\\images\\img_2.png: 480x640 1 person, Done. (0.522s)\n",
      "image 3/9 C:\\Working_Repositary\\flask-video-stream\\images\\img_3.png: 480x640 2 persons, Done. (0.333s)\n",
      "image 4/9 C:\\Working_Repositary\\flask-video-stream\\images\\img_4.png: 480x640 1 person, Done. (0.310s)\n",
      "image 5/9 C:\\Working_Repositary\\flask-video-stream\\images\\img_5.png: 480x640 3 persons, Done. (0.310s)\n",
      "image 6/9 C:\\Working_Repositary\\flask-video-stream\\images\\img_6.png: 480x640 1 person, Done. (0.353s)\n",
      "image 7/9 C:\\Working_Repositary\\flask-video-stream\\images\\img_7.png: 480x640 1 person, Done. (0.311s)\n",
      "image 8/9 C:\\Working_Repositary\\flask-video-stream\\images\\last.png: 480x640 Done. (0.319s)\n",
      "image 9/9 C:\\Working_Repositary\\flask-video-stream\\images\\not_found.jpeg: 640x640 Done. (0.431s)\n",
      "Speed: 2.8ms pre-process, 373.0ms inference, 2.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov5\\runs\\detect\\exp4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !cd flask-video-stream\n",
    "weight_path = 'yolov5/best.pt' #위에서 학습 시킨 모델 weight, exp 숫자 확인 \n",
    "data_path = 'images' #예측하고자 하는 이미지 디렉토리 \n",
    "!python yolov5/detect.py --weights {weight_path} --img 640 --conf 0.25 --source {data_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b4a666a3140e696faf634e3cbfbedada3b99a8ffe9c30d675d10e862f673a60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
